{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "from torch.utils.data import DataLoader"
      ],
      "metadata": {
        "id": "XAZpLdZmxBc6"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r5ZfHMFvvI1C",
        "outputId": "d84c27e8-3382-4dc7-9aa9-4d91b4723141"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Salida de la operación Inception con datos sintéticos:\n",
            "torch.Size([1, 256, 224, 224])\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class InceptionModule(nn.Module):\n",
        "    def __init__(self, in_channels, out1x1, red3x3, out3x3, red5x5, out5x5, pool_proj):\n",
        "        super(InceptionModule, self).__init__()\n",
        "\n",
        "        # 1x1 conv branch\n",
        "        self.branch1x1 = nn.Conv2d(in_channels, out1x1, kernel_size=1)\n",
        "\n",
        "        # 1x1 conv followed by 3x3 conv branch\n",
        "        self.branch3x3 = nn.Sequential(\n",
        "            nn.Conv2d(in_channels, red3x3, kernel_size=1),\n",
        "            nn.Conv2d(red3x3, out3x3, kernel_size=3, padding=1)\n",
        "        )\n",
        "\n",
        "        # 1x1 conv followed by 5x5 conv branch\n",
        "        self.branch5x5 = nn.Sequential(\n",
        "            nn.Conv2d(in_channels, red5x5, kernel_size=1),\n",
        "            nn.Conv2d(red5x5, out5x5, kernel_size=5, padding=2)\n",
        "        )\n",
        "\n",
        "        # 3x3 pool followed by 1x1 conv branch\n",
        "        self.branch_pool = nn.Sequential(\n",
        "            nn.MaxPool2d(kernel_size=3, stride=1, padding=1),\n",
        "            nn.Conv2d(in_channels, pool_proj, kernel_size=1)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Concatenate the output of each branch\n",
        "        return torch.cat([self.branch1x1(x), self.branch3x3(x), self.branch5x5(x), self.branch_pool(x)], dim=1)\n",
        "\n",
        "# Crear un tensor de datos sintéticos para probar la operación Inception\n",
        "synthetic_data = torch.randn(1, 3, 224, 224)  # Tamaño típico de una imagen\n",
        "\n",
        "# Crear una instancia de InceptionModule\n",
        "inception_module = InceptionModule(3, 64, 128, 128, 32, 32, 32)\n",
        "\n",
        "# Pasar los datos sintéticos a través de la operación Inception\n",
        "output_synthetic = inception_module(synthetic_data)\n",
        "print(\"Salida de la operación Inception con datos sintéticos:\")\n",
        "print(output_synthetic.shape)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torchvision import datasets, transforms\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "# Descargar el conjunto de datos CIFAR-10\n",
        "transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
        "\n",
        "train_dataset = datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)\n",
        "test_dataset = datasets.CIFAR10(root='./data', train=False, download=True, transform=transform)\n",
        "\n",
        "# Crear DataLoader para el conjunto de datos de entrenamiento y prueba\n",
        "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
        "\n",
        "# Obtener un lote de datos de entrenamiento para probar la operación Inception\n",
        "sample_data, _ = next(iter(train_loader))\n",
        "\n",
        "# Pasar el lote de datos a través de la operación Inception\n",
        "output_cifar10 = inception_module(sample_data)\n",
        "print(\"Salida de la operación Inception con datos de CIFAR-10:\")\n",
        "print(output_cifar10.shape)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8UexOt-OvmBC",
        "outputId": "1e34929e-d107-4f54-a68c-4168351087ef"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n",
            "Salida de la operación Inception con datos de CIFAR-10:\n",
            "torch.Size([32, 256, 32, 32])\n"
          ]
        }
      ]
    }
  ]
}